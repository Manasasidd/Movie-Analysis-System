{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075050af-6cf3-43cf-952b-dda13cb7322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "\n",
    "def read_csv_from_s3(bucket_name, object_key):\n",
    "    \n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Create a buffer\n",
    "    csv_buffer = BytesIO()\n",
    "    \n",
    "    # Get object from S3 and write it to buffer\n",
    "    s3_client.download_fileobj(bucket_name, object_key, csv_buffer)\n",
    "    \n",
    "    # Set the buffer's position to the start\n",
    "    csv_buffer.seek(0)\n",
    "    \n",
    "    # Read buffer into DataFrame\n",
    "    df = pd.read_csv(csv_buffer)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "  # Define the key of the file you want to process\n",
    "    datasource1 = 'movies.csv'\n",
    "    datasource2 = 'api_movie_data.csv'\n",
    "    \n",
    "    # Define your source and destination S3 bucket names\n",
    "    source_bucket = 'final-project-rawdata-group-5-sec-2'\n",
    "    destination_bucket = 'final-project-mergedata-group-5-sec-2'\n",
    "    \n",
    "    # Initialize S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # Convert the content to pandas DataFrames\n",
    "    csv_movie_df = read_csv_from_s3(source_bucket, datasource1)\n",
    "    api_movie_df = read_csv_from_s3(source_bucket, datasource2)\n",
    "    \n",
    "    # CSV movie Data Handling\n",
    "    # Split 'title' column into 'title' and 'year'\n",
    "    csv_movie_df['year'] = csv_movie_df['title'].str.extract(r'\\((\\d{4})\\)$')  # Extract year enclosed in parentheses at the end of the string\n",
    "    csv_movie_df['title'] = csv_movie_df['title'].str.replace(r'\\s\\(\\d{4}\\)$', '', regex=True)  # Remove the year from the 'title' column\n",
    "\n",
    "    # Data Merging\n",
    "    merged_df = pd.merge(csv_movie_df, api_movie_df, on='title', how='inner')\n",
    "        \n",
    "    # Select columns\n",
    "    columns_to_select = ['imdb_id', 'title', 'language', 'country', 'adult',\n",
    "                         'genres_x', 'budget', 'revenue', 'release_date', \n",
    "                         'runtime', 'popularity', 'avg_rating', 'people_rated']\n",
    "    \n",
    "    # Selecting the columns from dataset\n",
    "    selected_df = merged_df[columns_to_select]\n",
    "    \n",
    "    # Drop Duplicates\n",
    "    selected_df = selected_df.drop_duplicates(subset='imdb_id', keep='last')\n",
    "    \n",
    "    # Renaming the columns\n",
    "    selected_df = selected_df.rename(columns={\n",
    "        'genres_x': 'genres', \n",
    "    })\n",
    "    \n",
    "    # Convert the transformed DataFrame back to CSV format\n",
    "    transformed_csv = selected_df.to_csv(index=False)\n",
    "        \n",
    "    # Define the destination key where you want to store the transformed data\n",
    "    destination_key = 'final_movie_dataset.csv'\n",
    "\n",
    "    # Upload the transformed data to the destination S3 bucket\n",
    "    s3.put_object(Body=transformed_csv, Bucket=destination_bucket, Key=destination_key)\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': 'Transformation completed successfully!'\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
